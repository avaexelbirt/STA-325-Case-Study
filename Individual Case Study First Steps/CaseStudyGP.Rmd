---
title: "STA 325 Case Study"
author: "Grady Purcell"
output: html_document
---

Description: This is my original work for the case study EDA section of the analysis (before 10/16 meeting).

```{r}
## Loading the libraries 
library(tidyverse)
library(dplyr)
library(ggplot2)
# install.packages(moments)
library(moments)

## Loading the data
data <- read.csv("data_transformed.csv")

```

## EDA for Summary Statistics

### Mean
```{r}
# Histogram for the different input variables

# no transformations
ggplot(data, aes(x = mean)) +
  geom_histogram(fill = "skyblue", color = "black") +
  labs(title = "Histogram of Mean", x = "Mean", y = "Count")

# log transformed
ggplot(data, aes(x = log(mean))) +
  geom_histogram(fill = "purple", color = "black") +
  labs(title = "Histogram of log(Mean)", x = "log(Mean)", y = "Count")

# squared transformed
ggplot(data, aes(x = mean^2)) +
  geom_histogram(fill = "pink", color = "black") +
  labs(title = "Histogram of Mean^2", x = "Mean^2", y = "Count")

# square root transformed
ggplot(data, aes(x = sqrt(mean))) +
  geom_histogram(fill = "blue", color = "black") +
  labs(title = "Histogram of sqrt(Mean)", x = "sqrt(Mean)", y = "Count")

```

Mean is very right-skewed with the majority of the means concentrated around 0. log(Mean) does make the distribution more symmetric, but converts all of the values to negative which is less interpretable. 

### Standard Deviation
```{r}
# Histogram for the different input variables

# no transformations
ggplot(data, aes(x = sd)) +
  geom_histogram(fill = "skyblue", color = "black") +
  labs(title = "Histogram of Standard Deviation", x = "Standard Deviation", y = "Count")

# log transformed
ggplot(data, aes(x = log(sd))) +
  geom_histogram(fill = "purple", color = "black") +
  labs(title = "Histogram of log(Standard Deviation)", x = "log(Standard Deviation)", 
       y = "Count")

# squared transformed
ggplot(data, aes(x = sd^2)) +
  geom_histogram(fill = "pink", color = "black") +
  labs(title = "Histogram of Standard Deviation^2", x = "Standard Deviation^2", y = "Count")

# square root transformed
ggplot(data, aes(x = sqrt(sd))) +
  geom_histogram(fill = "blue", color = "black") +
  labs(title = "Histogram of sqrt(Standard Deviation)", x = "sqrt(Standard Deviation)", 
       y = "Count")

```

We notice a similar pattern in that Standard Deviation is also very right skewed with the majority of the values close to 0. Log transforming Standard Deviation does make the distribution more symmetric, but also negative which is less interpretable.

### Skewness
```{r}
# Histogram for the different input variables

# no transformations
ggplot(data, aes(x = skewness)) +
  geom_histogram(fill = "skyblue", color = "black") +
  labs(title = "Histogram of Skew", x = "Skew", y = "Count")

# log transformed
ggplot(data, aes(x = log(skewness))) +
  geom_histogram(fill = "purple", color = "black") +
  labs(title = "Histogram of log(Skew)", x = "log(Skew)", 
       y = "Count")

# squared transformed
ggplot(data, aes(x = skewness^2)) +
  geom_histogram(fill = "pink", color = "black") +
  labs(title = "Histogram of Skew^2", x = "Skew^2", y = "Count")

# square root transformed
ggplot(data, aes(x = sqrt(skewness))) +
  geom_histogram(fill = "blue", color = "black") +
  labs(title = "Histogram of sqrt(Skew)", x = "sqrt(Skew)", 
       y = "Count")
```

Skew has a bi-modal distribution with there being very few observations with a skew between 100 and 200. None of the transformations appear to improve the distribution of skew, often making the distribution tri-modal with clusters instead of more symmetric. For this reason, it might be best to stick with the untransformed values for skew.

### Kurtosis
```{r}
# Histogram for the different input variables

# no transformations
ggplot(data, aes(x = kurtosis)) +
  geom_histogram(fill = "skyblue", color = "black") +
  labs(title = "Histogram of Kurtosis", x = "Kurtosis", y = "Count")

# log transformed
ggplot(data, aes(x = log(kurtosis))) +
  geom_histogram(fill = "purple", color = "black") +
  labs(title = "Histogram of log(Kurtosis)", x = "log(Kurtosis)", 
       y = "Count")

# squared transformed
ggplot(data, aes(x = kurtosis^2)) +
  geom_histogram(fill = "pink", color = "black") +
  labs(title = "Histogram of Kurtosis^2", x = "Kurtosis^2", y = "Count")

# square root transformed
ggplot(data, aes(x = sqrt(kurtosis))) +
  geom_histogram(fill = "blue", color = "black") +
  labs(title = "Histogram of sqrt(Kurtosis)", x = "sqrt(Kurtosis)", 
       y = "Count")
```

Kurtosis is also right-skewed but not as drastically as mean and standard deviation above. Compared to the transformed distributions for Kurtosis, the untransformed distribution is more symmetric which would indicate that keeping kurtosis untransformed might yield the best results. 

```{r}
```{r}
## Converting to Summary Statistics

```{r}
# raw moments from training data
m1 <- data$R_moment_1   
m2 <- data$R_moment_2
m3 <- data$R_moment_3
m4 <- data$R_moment_4

# raw moments starting at 0
raw_mat0 <- cbind(m0 = 1, m1 = m1, m2 = m2, m3 = m3, m4 = m4)

# raw to central
central_all <- t(apply(raw_mat0, 1, raw2central))

output <- data.frame(
  mean        = m1, # mean- first raw moment
  mu2_central = central_all[, 3], # sd 
  mu3_central = central_all[, 4],
  mu4_central = central_all[, 5]
)

output$sd <- sqrt(output$mu2_central) # sd= sqrt(2nd central moment)
output$skewness <- output$mu3_central / (output$sd^3) # 3rd cm / sd^3
output$kurtosis <- output$mu4_central / (output$sd^4) #4th cm/ sd^4

central_moments_combined <- cbind(train, output)


```

## Distribution of St, Re, Fr

### St: size of particles

```{r}
# Histogram for the different input variables

ggplot(data, aes(x = St)) +
  geom_histogram(binwidth = 0.1, fill = "skyblue", color = "black") +
  labs(title = "Histogram of St", x = "St", y = "Count")

```

```{r}
# Finding whether there are any outliers
quartiles_st <- quantile(data$St, probs = c(0.25, 0.5, 0.75))
IQR_value_st <- (quartiles_st[[3]] - quartiles_st[[1]]) * 1.5

# Outliers would be above or below
lower_bound_st <- quartiles_st[[1]] - IQR_value_st
upper_bound_st <- quartiles_st[[3]] + IQR_value_st
print(lower_bound_st)
print(upper_bound_st)
```

Notice: St is right skewed with several outliers above the 2.05 range. It might be worth further exploring transforming this variable.

### Re: intensity of the turbulence within the flow

```{r}
# Histogram for the different input variables

ggplot(data, aes(x = Re)) +
  geom_histogram(fill = "skyblue", color = "black") +
  labs(title = "Histogram of Re", x = "Re", y = "Count")

# Finding the unique values of Re
unique(data$Re)
table(data$Re)
```

It is interesting that Re only has 3 possible values: 90, 224, 398. This likely means that there are three main types of clouds so it might be advantageous to try and determine which clouds are which. It appears as though 398 is the least frequent Re value while 224 is the most frequent.

### Fr: degree of gravitation acceleration experienced by the flow

Note: This variable has infinite values

```{r}
# Histogram for the different input variables

ggplot(data, aes(x = Fr)) +
  geom_histogram(fill = "skyblue", color = "black") +
  labs(title = "Histogram of Fr", x = "Fr", y = "Count")

# Finding the unique values of Re
table(data$Fr)


```

Similarily to Re above, Fr only has three possible values: 0.052, 0.300, and Inf. The distribution of these variables is fairly even with 0.052 being the most common value and 0.3 being the least common value. We are going to have to determine how we want to handle infinite Fr values.

From class, we know that lower hanging clouds have a higher Fr value so we could assume that those with infinite Fr are likely to be lower hanging.

**QUESTION**: Should 0.3 or Infinity be treated as a higher Fr value for lower hanging clouds?

**QUESTION:** What does an infinite Fr value mean? What is causing them?

-   Given the magnitude of the other values for Fr, I would assume they are being caused by a division by 0 error.

-   Froud Number = V / sqrt(gL) so likely g or L is negative where g is acceleration due to gravity and L is characteristic length of the flow. (g is likely 0)

## Examining Distribution of Central Moments

### Mean

```{r}
# Histogram for the central moments

ggplot(data, aes(x = Mean)) +
  geom_histogram(fill = "skyblue", color = "black") +
  labs(title = "Histogram of Means", x = "Mean", y = "Count")

```

```{r}
# Finding whether there are any outliers
quartiles_mean <- quantile(data$Mean, probs = c(0.25, 0.5, 0.75))
IQR_value_mean <- (quartiles_mean[[3]] - quartiles_mean[[1]]) * 1.5

# Outliers would be above or below
lower_bound_mean <- quartiles_mean[[1]] - IQR_value_mean
upper_bound_mean <- quartiles_mean[[3]] + IQR_value_mean
print(lower_bound_mean)
print(upper_bound_mean)
```

It is clear that mean is right skewed with the majority of the mean values less than 0.25. There is an outlier above 1 which is greatly outside of the IQR range and should likely be handled with a log transformation. However, some of the mean values are negative so they can't be log transformed.

Explore a log transformation of the mean â€“ since some values are negative, I am going to add a constant to each of the values so that they are positive and then log-transform them

```{r}
# Log transforming the mean
shift <- abs(min(data$Mean)) + 0.1
train$log_Mean <- log(data$Mean + shift)

# Histogram for the log-transformed meean
ggplot(data, aes(x = log_Mean)) +
  geom_histogram(fill = "skyblue", color = "black") +
  labs(title = "Histogram of Log Means", x = "Log Mean", y = "Count")

```

Log transforming made the distribution a little more symmetric, although there still appears to be an outlier.

### Standard Deviation

```{r}
# Histogram for the central moments

ggplot(data, aes(x = Standard_deviation)) +
  geom_histogram(fill = "skyblue", color = "black") +
  labs(title = "Histogram of SD", x = "SD", y = "Count")
```

It appears as though SD around 0 is most common although none of the standard deviations are repeated. They are distributed fairly evenly to the right and left of 0 with few observations which is a good thing.

Transforming the standard deviation:

```{r}

data$sd_trans <- sign(data$Standard_deviation) * sqrt(abs(data$Standard_deviation))

ggplot(data, aes(x = sd_trans)) +
  geom_histogram(fill = "skyblue", color = "black") +
  labs(title = "Histogram of SD Transformed", x = "SD Transformed", y = "Count")
```

The above transformation which takes the square root and maintains the sign is a bit better in terms of having the distribution closer to 0. However, this may be difficult to justify.

### Skewness

```{r}
# Histogram for the central moments

ggplot(data, aes(x = Skewness)) +
  geom_histogram(fill = "skyblue", color = "black") +
  labs(title = "Histogram of Skewness", x = "Skewness", y = "Count")
```

It is clear that there is one outlier to the left of the graph which is clearly skewing the distribution for skewness.

```{r}
# Want to remove the outlier and re-plot the distribution
Skewness <- data.frame(data$Skewness)
Skewness <- Skewness |>
  filter(data.Skewness > -1.602621e+160)

ggplot(Skewness, aes(x = data.Skewness)) +
  geom_histogram(fill = "skyblue", color = "black") +
  labs(title = "Histogram of Skewness", x = "Skewness", y = "Count")
```

The distribution of skewness is still very weird despite having removed some of the outliers.

### Kurtosis

```{r}
# Histogram for the central moments

ggplot(data, aes(x = Kurtosis)) +
  geom_histogram(fill = "skyblue", color = "black") +
  labs(title = "Histogram of Kurtosis", x = "Kurtosis", y = "Count")
```

We notice that Kurtosis has a similarly weird distribution as Skewness above.

## Variable Transformation

For now, assume that the Inf Fr values should be replaced with 0's. (Not sure if this is a fair assumption). We also will need to transform Kurtosis since it has both Infinite and NaN values - for now just replace with 0.

```{r}
# Replace infinite values with 0

data_new <- data |>
  mutate(across(
    where(is.numeric),
    ~ ifelse(is.infinite(.x) | is.nan(.x), 0, .x)
  ))

```

For now, I am going to not transform any of the variables because I want to see how the model performs before transformation. I also think it's valuable for us to discuss transformation more as a group before fitting different models.

## Train-Test Split

```{r}
set.seed(325)

# Getting the appropriate sizes for the dataframe
sample_size <- floor(0.8 * nrow(data_new))

train_indices <- sample(seq_len(nrow(data_new)), 
                        size = sample_size)

# Doing the train-test split
train <- data_new[train_indices, ]
test  <- data_new[-train_indices, ]
```

## Baseline Linear Model

### Mean

```{r}
# Building the baseline linear model

linear_model_mean <- lm(Mean ~ Re + Fr + St, data = data_new)
summary(linear_model_mean)
```

The R\^2 value is very low for the model above which indicates a linear model may not be the best fit.

### Standard Deviation

```{r}
# Building the baseline linear model

linear_model_sd <- lm(Standard_deviation ~ Re + Fr + St, 
                      data = data_new)
summary(linear_model_sd)
```

This R\^2 value is even lower than for mean, so we likely need to fit more complex models.

### Skewness

```{r}
# Building the baseline linear model

linear_model_skew <- lm(Skewness ~ Re + Fr + St, 
                      data = data_new)
summary(linear_model_skew)
```

The linear model doesn't even work for this model. I am unsure why this is the case but clearly a more flexible model is required.

### Kurtosis

```{r}
# Building the baseline linear model

linear_model_kurtosis <- lm(Kurtosis ~ Re + Fr + St, 
                      data = data_new)
summary(linear_model_kurtosis)
```

Similar problem above where the model doesn't really work for the kurtosis values.

## Next Steps:

-   Determine how to handle Fr & Kurtosis when they have NA or Infinite Values

-   Think about which models are most appropriate for each of the central moments based on the distributions of these moments.
