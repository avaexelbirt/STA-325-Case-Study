---
title: "STA 325 Case Study"
author: "Ella Tillinghast"
output: html_document
---
This is what I came up with for our first steps!

### Load Data + Libraries
```{r}

library(tidyverse)
library(tidymodels)
library(dplyr)
library(broom)
library(car)
library(ggplot2)
library(MuMIn)
library(splines)
library(GGally)
library(readr)
library(reshape2)
library(corrplot)

data <- read.csv("/home/guest/STA-325-Case-Study/Data/data-train.csv")
test <- read.csv("/home/guest/STA-325-Case-Study/Data/data-test.csv")


```

```{r}
# convert raw moments to central moments
library(moments)

# raw moments from training data
m1 <- data$R_moment_1   
m2 <- data$R_moment_2
m3 <- data$R_moment_3
m4 <- data$R_moment_4

# raw moments starting at 0
raw_mat0 <- cbind(m0 = 1, m1 = m1, m2 = m2, m3 = m3, m4 = m4)

# raw to central
central_all <- t(apply(raw_mat0, 1, raw2central))

output <- data.frame(
  mean        = m1, # mean- first raw moment
  mu2_central = central_all[, 3], # sd 
  mu3_central = central_all[, 4],
  mu4_central = central_all[, 5]
)

output$sd <- sqrt(output$mu2_central) # sd= sqrt(2nd central moment)
output$skewness <- output$mu3_central / (output$sd^3) # 3rd cm / sd^3
output$kurtosis <- output$mu4_central / (output$sd^4) #4th cm/ sd^4

central_moments_combined <- cbind(data, output)

### Understanding the data

```

```{r}

str(data)

summary(data)

colSums(is.na(data))


```


### Distribution of Moments RAW
```{r}
moment_cols <- c("R_moment_1", "R_moment_2", "R_moment_3", "R_moment_4")

for (col in moment_cols) {
  print(
    ggplot(data, aes_string(x = col)) +
      geom_histogram(bins = 30, fill = "#69b3a2", color = "white") +
      theme_minimal() +
      labs(title = paste("Distribution of", col))
  )
}
```

### Transformations RAW

```{r}
ggplot(data, aes(x = log1p(R_moment_1))) + geom_histogram(fill = "#69b3a2") +
  labs(title = "R_moment_1_logged")

ggplot(data, aes(x = log1p(R_moment_2))) + geom_histogram(fill = "#69b3a2") +
  labs(title = "R_moment_2_logged")

ggplot(data, aes(x = log1p(R_moment_3))) + geom_histogram(fill = "#69b3a2") +
  labs(title = "R_moment_3_logged")

ggplot(data, aes(x = log1p(R_moment_4))) + geom_histogram(fill = "#69b3a2") +
  labs(title = "R_moment_4_logged")

```
Applying a log helps to stablize data across all moments (clearer/easier to read)


### Correlation RAW
```{r}

num_vars_Re <- data[, c("Re", moment_cols)]
cor_mat <- cor(num_vars_Re, use = "complete.obs")

corrplot(cor_mat, method = "color", type = "upper", tl.cex = 0.8)


num_vars_St <- data[, c("St", moment_cols)]
cor_mat <- cor(num_vars_St, use = "complete.obs")

corrplot(cor_mat, method = "color", type = "upper", tl.cex = 0.8)

num_vars_Fr <- data[, c("Fr", moment_cols)]
cor_mat <- cor(num_vars_Fr, use = "complete.obs")

corrplot(cor_mat, method = "color", type = "upper", tl.cex = 0.8)
```

### Group-Level Patterns (I think I should log the vars) RAW
```{r}

data %>%
group_by(St) %>%
summarise(across(all_of(moment_cols),
list(mean = mean, sd = sd),
na.rm = TRUE)) %>%
pivot_longer(-St, names_to = c("Moment", ".value"),
names_pattern = "(.*)_(mean|sd)") %>%
ggplot(aes(x = St, y = mean, fill = Moment)) +
geom_bar(stat = "identity", position = position_dodge()) +
geom_errorbar(aes(ymin = mean - sd, ymax = mean + sd),
position = position_dodge(0.9), width = 0.2) +
theme_minimal() +
labs(title = "Average Moments by St (with SD error bars)",
x = "St", y = "Mean Moment")


```

## VOID RAW
```{r}

## Fix
m_logr1 <- lm(log1p(R_moment_1) ~ Re + St + Fr, data = data)


summary(m_logr1)

par(mfrow = c(2, 2))
plot(m_logr1)
par(mfrow = c(1, 1))


test <- test %>%
  mutate(R1_log = log1p(R_moment_1)) %>%
  drop_na(Re, St, Fr, R1_log)

pred_m_logr1 <- predict(m_logr1, newdata = test)

rmse_logr1 <- sqrt(mean((pred_m_logr1 - test$R1_log)^2))
r2_logr1 <- cor(pred_m_logr1, test$R1_log)^2

cat("m_logr1 — Test RMSE:", rmse_logr1, "\n")
cat("m_logr1 — Test R²:", r2_logr1, "\n")

ggplot(test, aes(x = R1_log, y = pred_m_logr1)) +
  geom_point(alpha = 0.4) +
  geom_abline(slope = 1, intercept = 0, color = "red") +
  theme_minimal() +
  labs(
    title = "m_logr1: Predicted vs Actual (Test Set)",
    x = "Actual log1p(R_moment_1)",
    y = "Predicted"
  )


```


```{r}
data <- central_moments_combined |>
  mutate(log_St = log(St), 
         log_Re = log(Re),
         St_2 = St**2,
         Re_2 = Re**2,
         Fr_2 = Fr**2,
         St_sqrt = sqrt(St),
         Re_sqrt = sqrt(Re),
         logistic_Fr = 1/(1+exp(-Fr)))
```


### Focus on SKEW


#### LINEAR
```{r}

linskew <- lm(R_moment_3 ~ St + Re + logistic_Fr, data = data)

tidy(linskew)

## Had to do log Fr otherwise it does not run
```

#### POLYNOMIAL
```{r}

polyskew <- lm(R_moment_3 ~ St + I(St^2) + Re + I(Re^2) + logistic_Fr + I(logistic_Fr^2),
                 data = data)

tidy(polyskew)
```

#### RIDGE
```{r}
# Convert predictors to matrix
X <- model.matrix(R_moment_3 ~ St + Re + logistic_Fr, data = data)[, -1]
y <-data$R_moment_3

# Ridge model
ridge_fit <- cv.glmnet(X, y, alpha = 0, standardize = FALSE)

# Best lambda
ridge_lambda <- ridge_fit$lambda.min

ridskew <- glmnet(X, y, alpha = 0, lambda = ridge_lambda, standardize = FALSE)
coef(ridskew)

```

#### LASSO

```{r}
# Lasso model
lasso_fit1 <- cv.glmnet(X, y, alpha = 1, standardize = FALSE)
lasso_lambda <- lasso_fit$lambda.min

lasskew <- glmnet(X, y, alpha = 1, lambda = lasso_lambda, standardize = FALSE)
coef(lasskew)

```

#### SPLINE
```{r}
# Using splines on the predictors
splineskew <- lm(R_moment_3 ~ ns(St, df = 3) + ns(Re, df = 3) + ns(logistic_Fr, df = 3),
                   data = data)

tidy(splineskew)

```

### COMPARING SKEW MODELS
```{r}
AIC(polyskew, splineskew)
# Cross-validation error for penalized models
ridge_fit$cvm[which.min(ridge_fit$cvm)]
lasso_fit$cvm[which.min(lasso_fit$cvm)]

```



### Focus on KURTOSIS

#### LINEAR
```{r}

linkurt <- lm(R_moment_4 ~ St + Re + logistic_Fr, data = data)

tidy(linkurt)

## Had to do log Fr otherwise it does not run
```

#### POLYNOMIAL
```{r}

polykurt <- lm(R_moment_4 ~ St + I(St^2) + Re + I(Re^2) + logistic_Fr + I(logistic_Fr^2),
                 data = data)

tidy(polykurt)
```

#### RIDGE
```{r}
# Convert predictors to matrix
W <- model.matrix(R_moment_4 ~ St + Re + logistic_Fr, data = data)[, -1]
v <-data$R_moment_4

# Ridge model
ridge_fit2 <- cv.glmnet(W, v, alpha = 0, standardize = FALSE)

# Best lambda
ridge_lambda2 <- ridge_fit2$lambda.min

ridkurt <- glmnet(W, v, alpha = 0, lambda = ridge_lambda2, standardize = FALSE)
coef(ridkurt)

```

#### LASSO

```{r}
# Lasso model
lasso_fit2 <- cv.glmnet(W, v, alpha = 1, standardize = FALSE)
lasso_lambda2 <- lasso_fit2$lambda.min

laskurt <- glmnet(W, v, alpha = 1, lambda = lasso_lambda2, standardize = FALSE)
coef(laskurt)

```

#### SPLINE
```{r}
# Using splines on the predictors
splinekurt <- lm(R_moment_4 ~ ns(St, df = 3) + ns(Re, df = 3) + ns(logistic_Fr, df = 3),
                   data = data)

tidy(splinekurt)

```

### COMPARING KURTOSIS MODELS
```{r}
AIC(polykurt, splinekurt)
# Cross-validation error for penalized models
ridge_fit2$cvm[which.min(ridge_fit2$cvm)]
lasso_fit2$cvm[which.min(lasso_fit2$cvm)]

```
